name: Weekly news fetch

on:
  schedule:
    # 매주 월요일 00:30 UTC (한국 09:30)
    - cron: "30 0 * * 1"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  fetch-news:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          pip install feedparser beautifulsoup4

      - name: Build summarized news JSON
        run: |
          python - << 'PY'
          import os, json, re, datetime
          from urllib.parse import quote
          import feedparser
          from bs4 import BeautifulSoup

          def clean(txt):
              if not txt: return ''
              soup = BeautifulSoup(txt, 'html.parser')
              t = soup.get_text(' ', strip=True)
              t = re.sub(r'\s+', ' ', t)
              return t

          def summarize(text, limit=200):
              if not text: return ''
              parts = re.split(r'(?<=[.!?])\s+', text)
              s = ' '.join(parts[:2])
              return (s[:limit] + '…') if len(s)>limit else s

          def fetch_section(query, max_items=5):
              url=f"https://news.google.com/rss/search?q={quote(query)}&hl=en&gl=US&ceid=US:en"
              d=feedparser.parse(url)
              items=[]
              for e in d.entries[:max_items]:
                  title=clean(getattr(e,'title',''))
                  link=getattr(e,'link','')
                  desc=clean(getattr(e,'summary',''))
                  full=desc or title
                  summ=summarize(full)
                  items.append({"title":title,"url":link,"summary":summ})
              return items

          def analyze_invest(sections):
              tips=[]
              econ_text=" ".join(a["summary"] for a in sections.get("economy",[]))
              if any(k in econ_text.lower() for k in ["inflation","cpi","price"]):
                  tips.append("📉 물가·CPI 뉴스 → 성장주(NASDAQ) 변동성 ↑, 금리 부담")
              if any(k in econ_text.lower() for k in ["jobs","employment","unemployment"]):
                  tips.append("💼 고용지표 강세 → 경기 견조 → 금융·산업주 유리")
              if any(k in econ_text.lower() for k in ["fed","interest","rate"]):
                  tips.append("🏦 연준 금리 뉴스 → 방어주·배당주 관심 필요")
              if any(k in econ_text.lower() for k in ["tech","ai","semiconductor","chip"]):
                  tips.append("🤖 기술·반도체 뉴스 → 장기 성장 모멘텀 유지")
              if not tips:
                  tips.append("⚖️ 뚜렷한 신호 없음 → 분산 투자 유지 권장")
              return " / ".join(tips)

          sections = {
              "politics": fetch_section("US politics White House Congress"),
              "economy": fetch_section("US economy CPI jobs inflation"),
              "society": fetch_section("US society crime culture education"),
              "world":   fetch_section("world geopolitics war conflict"),
          }

          wrap = " / ".join(v[0]["summary"] for v in sections.values() if v)

          invest = analyze_invest(sections)

          out = {
              "date": datetime.date.today().isoformat(),
              "sections": sections,
              "wrap_summary": wrap,
              "invest_summary": invest
          }

          os.makedirs("data", exist_ok=True)
          with open("data/news.json","w",encoding="utf-8") as f:
              json.dump(out,f,ensure_ascii=False,indent=2)
          PY

      - name: Commit & push
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          if git diff --cached --quiet; then
            echo "No changes"
          else
            git commit -m "chore(data): weekly news update [skip ci]"
            git push
          fi
