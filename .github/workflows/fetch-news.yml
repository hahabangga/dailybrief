name: Daily news fetch (RSS summarizer, daily)

on:
  schedule:
    # 매일 06:55 KST (UTC 21:55)
    - cron: "55 21 * * *"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  fetch-news:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install feedparser beautifulsoup4 lxml yake requests

      - name: Build summarized news JSON (RSS-only, force daily change)
        run: |
          python - << 'PY'
          import os, json, re, datetime
          from urllib.parse import quote
          import feedparser
          from bs4 import BeautifulSoup
          import yake

          # ---------- helpers ----------
          def clean_html(txt):
            if not txt: return ''
            soup = BeautifulSoup(txt, 'html.parser')
            t = soup.get_text(' ', strip=True)
            return re.sub(r'\s+', ' ', t).strip()

          def fetch_rss(query, max_items=7, hl='en', gl='US', ceid='US:en'):
            url=f"https://news.google.com/rss/search?q={quote(query)}&hl={hl}&gl={gl}&ceid={ceid}"
            d=feedparser.parse(url)
            out=[]
            for e in d.entries[:max_items]:
              out.append({
                "title": clean_html(getattr(e,'title','')),
                "url":   getattr(e,'link',''),
                "desc":  clean_html(getattr(e,'summary','')),
                "published": getattr(e,'published','')
              })
            return out

          def sentence_split(text):
            if not text: return []
            s = re.split(r'(?<=[\.\?\!])\s+|(?<=\.)\s+|(?<=\?)\s+|(?<=!)\s+', text)
            return [x.strip() for x in s if len(x.strip().split())>=4]

          def top_keywords(text, topk=10):
            try:
              ex=yake.KeywordExtractor(lan="en", n=1, top=topk)
              kws=ex.extract_keywords(text)
              ranked=[(k,1.0/(s+1e-9)) for k,s in kws if k]
              tot=sum(w for _,w in ranked) or 1.0
              return {k:w/tot for k,w in ranked}
            except Exception:
              return {}

          def score_sentence(sent, kw):
            s=sent.lower(); sc=0.0
            for k,w in kw.items():
              if k.lower() in s: sc += s.count(k.lower())*w
            if re.search(r'(\d{1,3}(?:,\d{3})*(?:\.\d+)?%|\$\d+(?:\.\d+)?|\d{4})', sent):
              sc *= 1.15
            return sc

          def summarize_from_rss(title, desc, n=2):
            base = ((desc or '').strip() + ' ' + (title or '').strip()).strip()
            if not base: return ''
            sents = sentence_split(base)
            if not sents: return base[:220]
            kw = top_keywords(base)
            scored=sorted(((score_sentence(s,kw),s) for s in sents), reverse=True)
            picks=[]
            def overlap(a,b):
              sa=set(a.lower().split()); sb=set(b.lower().split())
              return (len(sa&sb)/len(sa|sb)) if sa and sb else 0
            for _,sent in scored:
              if all(overlap(sent,p)<0.65 for p in picks):
                picks.append(sent)
              if len(picks)>=n: break
            return " ".join(picks) if picks else base[:220]

          def key_figures(text):
            figs = re.findall(r'(\d{1,3}(?:,\d{3})*(?:\.\d+)?%|\$\d+(?:\.\d+)?|\d\.\d%|\d{4})', text or '')
            uniq=[]
            for x in figs:
              if x not in uniq: uniq.append(x)
            return uniq[:6]

          def why_matters(tag_text):
            s=(tag_text or '').lower()
            if any(k in s for k in ['inflation','cpi','price','jobs','employment','unemployment','payroll','fed','rate','interest']):
              return "경제·금리 경로에 영향."
            if any(k in s for k in ['war','conflict','sanction','geopolitics','energy','oil']):
              return "지정학·공급망 리스크."
            if any(k in s for k in ['regulation','antitrust','policy','congress','white house']):
              return "정책/규제 변화 가능."
            return "핵심 동향 파악."

          def build_section(query, section_key, hl='en', gl='US', ceid='US:en', max_items=7):
            items = fetch_rss(query, max_items=max_items, hl=hl, gl=gl, ceid=ceid)
            out=[]
            for it in items:
              base_text = f"{it['title']} {it['desc']}".strip()
              summ = summarize_from_rss(it['title'], it['desc'], n=2)
              out.append({
                "title": it["title"],
                "url": it["url"],
                "summary": summ,
                "published": it["published"],
                "key_figures": key_figures(base_text),
                "why_matters": why_matters(base_text),
                "whats_next": "후속 지표/발표 모니터.",
              })
            return out

          # ---------- sections ----------
          sections = {
            # 미국: 영어 피드
            "us": build_section(
              "US CPI OR FOMC OR jobs OR inflation OR earnings OR regulation OR geopolitics",
              "us", hl='en', gl='US', ceid='US:en', max_items=7
            ),
            # 한국: 한국어 피드
            "kr": build_section(
              "한국 경제 OR 금리 OR 물가 OR 고용 OR 규제 OR 수출 OR 지정학",
              "kr", hl='ko', gl='KR', ceid='KR:ko', max_items=7
            ),
            # 세계: 영어 피드
            "world": build_section(
              "global economy OR geopolitics OR war OR oil OR supply chain OR sanctions",
              "world", hl='en', gl='US', ceid='US:en', max_items=7
            ),
          }

          # 상단 요약(간단 연결)
          wrap = " / ".join((v[0]["summary"] if v else "") for v in sections.values() if v)

          # 투자 시사점(간단 규칙)
          def invest_insight(sections):
            tips=[]
            econ = " ".join(i["summary"] for i in sections.get("us",[])+sections.get("world",[])).lower()
            if any(k in econ for k in ['inflation','cpi','price']): tips.append("물가 경계: 성장주 변동성↑, 방어주 관심.")
            if any(k in econ for k in ['jobs','employment','unemployment','payroll']): tips.append("고용 견조 시 경기민감·금융에 우호적.")
            if any(k in econ for k in ['fed','rate','interest']): tips.append("금리 경로 주시: 금리민감주 변동성 확대.")
            if any(k in econ for k in ['ai','semiconductor','chip','nvidia','foundry']): tips.append("AI/반도체 모멘텀 지속 여부 체크.")
            if not tips: tips.append("뚜렷한 방향성 신호 부족: 분산과 현금 비중 관리.")
            return " / ".join(tips)

          invest = invest_insight(sections)

          today = datetime.date.today().isoformat()
          generated_at = datetime.datetime.utcnow().isoformat(timespec='seconds') + "Z"

          out = {
            "date": today,
            "generated_at": generated_at,  # <- 매일 달라져서 커밋이 항상 발생
            "sections": {
              "politics": [],    # (구버전 호환: 비워둠)
              "economy": [],     # (구버전 호환: 비워둠)
              "society": [],     # (구버전 호환: 비워둠)
              "world": sections["world"],
            },
            "regions": {         # <- 새 구조(권장)
              "us": sections["us"],
              "kr": sections["kr"],
              "world": sections["world"]
            },
            "wrap_summary": wrap,
            "invest_summary": invest
          }

          os.makedirs("data", exist_ok=True)
          with open("data/news.json","w",encoding="utf-8") as f:
            json.dump(out,f,ensure_ascii=False,indent=2)

          print("Wrote data/news.json at", generated_at)
          PY

      - name: Commit & push (force daily change)
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "chore(data): daily news update (auto) [skip ci]" || echo "No changes to commit"
          git push || echo "Nothing to push"
