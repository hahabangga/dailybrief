name: Weekly news fetch

on:
  schedule:
    # ë§¤ì£¼ ì›”ìš”ì¼ 00:30 UTC (í•œêµ­ 09:30)
    - cron: "30 0 * * 1"
  workflow_dispatch:

permissions:
  contents: write

jobs:
  fetch-news:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          pip install feedparser beautifulsoup4

      - name: Build summarized news JSON
        run: |
          python - << 'PY'
          import os, json, re, datetime
          from urllib.parse import quote
          import feedparser
          from bs4 import BeautifulSoup

          def clean(txt):
              if not txt: return ''
              soup = BeautifulSoup(txt, 'html.parser')
              t = soup.get_text(' ', strip=True)
              t = re.sub(r'\s+', ' ', t)
              return t

          def summarize(text, limit=200):
              if not text: return ''
              parts = re.split(r'(?<=[.!?])\s+', text)
              s = ' '.join(parts[:2])
              return (s[:limit] + 'â€¦') if len(s)>limit else s

          def fetch_section(query, max_items=5):
              url=f"https://news.google.com/rss/search?q={quote(query)}&hl=en&gl=US&ceid=US:en"
              d=feedparser.parse(url)
              items=[]
              for e in d.entries[:max_items]:
                  title=clean(getattr(e,'title',''))
                  link=getattr(e,'link','')
                  desc=clean(getattr(e,'summary',''))
                  full=desc or title
                  summ=summarize(full)
                  items.append({"title":title,"url":link,"summary":summ})
              return items

          def analyze_invest(sections):
              tips=[]
              econ_text=" ".join(a["summary"] for a in sections.get("economy",[]))
              if any(k in econ_text.lower() for k in ["inflation","cpi","price"]):
                  tips.append("ğŸ“‰ ë¬¼ê°€Â·CPI ë‰´ìŠ¤ â†’ ì„±ì¥ì£¼(NASDAQ) ë³€ë™ì„± â†‘, ê¸ˆë¦¬ ë¶€ë‹´")
              if any(k in econ_text.lower() for k in ["jobs","employment","unemployment"]):
                  tips.append("ğŸ’¼ ê³ ìš©ì§€í‘œ ê°•ì„¸ â†’ ê²½ê¸° ê²¬ì¡° â†’ ê¸ˆìœµÂ·ì‚°ì—…ì£¼ ìœ ë¦¬")
              if any(k in econ_text.lower() for k in ["fed","interest","rate"]):
                  tips.append("ğŸ¦ ì—°ì¤€ ê¸ˆë¦¬ ë‰´ìŠ¤ â†’ ë°©ì–´ì£¼Â·ë°°ë‹¹ì£¼ ê´€ì‹¬ í•„ìš”")
              if any(k in econ_text.lower() for k in ["tech","ai","semiconductor","chip"]):
                  tips.append("ğŸ¤– ê¸°ìˆ Â·ë°˜ë„ì²´ ë‰´ìŠ¤ â†’ ì¥ê¸° ì„±ì¥ ëª¨ë©˜í…€ ìœ ì§€")
              if not tips:
                  tips.append("âš–ï¸ ëšœë ·í•œ ì‹ í˜¸ ì—†ìŒ â†’ ë¶„ì‚° íˆ¬ì ìœ ì§€ ê¶Œì¥")
              return " / ".join(tips)

          sections = {
              "politics": fetch_section("US politics White House Congress"),
              "economy": fetch_section("US economy CPI jobs inflation"),
              "society": fetch_section("US society crime culture education"),
              "world":   fetch_section("world geopolitics war conflict"),
          }

          wrap = " / ".join(v[0]["summary"] for v in sections.values() if v)

          invest = analyze_invest(sections)

          out = {
              "date": datetime.date.today().isoformat(),
              "sections": sections,
              "wrap_summary": wrap,
              "invest_summary": invest
          }

          os.makedirs("data", exist_ok=True)
          with open("data/news.json","w",encoding="utf-8") as f:
              json.dump(out,f,ensure_ascii=False,indent=2)
          PY

      - name: Commit & push
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          if git diff --cached --quiet; then
            echo "No changes"
          else
            git commit -m "chore(data): weekly news update [skip ci]"
            git push
          fi
